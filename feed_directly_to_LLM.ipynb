{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pdb\n",
    "\n",
    "# Scienfitic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "from torch import cuda\n",
    "torch.set_grad_enabled(False)\n",
    "from tqdm  import tqdm\n",
    "\n",
    "# Visuals\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\",\n",
    "        rc={\"font.size\":16,\n",
    "            \"axes.titlesize\":16,\n",
    "            \"axes.labelsize\":16,\n",
    "            \"xtick.labelsize\": 16.0,\n",
    "            \"ytick.labelsize\": 16.0,\n",
    "            \"legend.fontsize\": 16.0})\n",
    "palette_ = sns.color_palette(\"Set1\")\n",
    "palette = palette_[2:5] + palette_[7:]\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Utilities\n",
    "\n",
    "from general_utils import (\n",
    "  ModelAndTokenizer,\n",
    "  make_inputs,\n",
    "  decode_tokens,\n",
    "  find_token_range,\n",
    "  predict_from_input,\n",
    ")\n",
    "\n",
    "from patchscopes_utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_hook = {\n",
    "    \"EleutherAI/pythia-6.9b\": set_hs_patch_hooks_neox,\n",
    "    \"/data3/MODELS/EleutherAI_pythia-12b\": set_hs_patch_hooks_neox_batch,\n",
    "    \"meta-llama/Llama-2-13b-hf\": set_hs_patch_hooks_llama,\n",
    "    \"lmsys/vicuna-7b-v1.5\": set_hs_patch_hooks_llama,\n",
    "    \"./stable-vicuna-13b\": set_hs_patch_hooks_llama,\n",
    "    \"CarperAI/stable-vicuna-13b-delta\": set_hs_patch_hooks_llama,\n",
    "    \"/data3/MODELS/gpt-j-6b\": set_hs_patch_hooks_gptj_batch,\n",
    "    \"/data3/MODELS/Meta-Llama-3-8B-Instruct/\":set_hs_patch_hooks_llama,\n",
    "    \"/data3/MODELS/llama2-hf/llama-2-13b-chat\":set_hs_patch_hooks_llama_batch,\n",
    "    \"/data3/MODELS/llama2-hf/llama-2-13b\":set_hs_patch_hooks_llama_batch,\n",
    "    \"/data3/MODELS/Mistral-7B-Instruct-v0.2\":set_hs_patch_hooks_mistral_batch,\n",
    "    \"/data3/MODELS/Qwen/Qwen2.5-7B-Instruct\" : set_hs_patch_hooks_qwen_batch,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9093853dd14a778e51e60bb963f3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "\n",
    "# 0-shot with GPT-J\n",
    "model_name = \"/data3/MODELS/llama2-hf/llama-2-13b\"\n",
    "sos_tok = False\n",
    "\n",
    "if \"13b\" in model_name or \"12b\" in model_name:\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = None\n",
    "\n",
    "my_device = torch.device(\"cuda:5\")\n",
    "\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=my_device,\n",
    ")\n",
    "mt.set_hs_patch_hooks = model_to_hook[model_name]\n",
    "mt.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(task_type, task_name, data_dir, output_dir, batch_size=1, n_samples=-1,\n",
    "                   save_output=True, replace=False, only_correct=True, is_icl=True):\n",
    "    fdir_out = f\"{output_dir}/{task_type}\"\n",
    "    fname_out = f\"{fdir_out}/{task_name}_only_correct_{only_correct}.pkl\"\n",
    "    # if not replace and os.path.exists(fname_out):\n",
    "    #     print(f\"File {fname_out} exists. Skipping...\")\n",
    "    #     return\n",
    "    print(f\"Running experiment on {task_type}/{task_name}...\")\n",
    "    df = pd.read_pickle(f\"{data_dir}/{task_type}/{task_name}.pkl\")\n",
    "    pd.set_option('display.max_columns',1000)   # 设置最大显示列数的多少\n",
    "    pd.set_option('display.width',1000)         # 设置宽度,就是说不换行,比较好看数据\n",
    "    if only_correct:\n",
    "        df = df[df[\"is_correct_baseline\"]].reset_index(drop=True)\n",
    "    # Dropping empty prompt sources. This is an artifact of saving and reloading inputs\n",
    "    df = df[~df[\"prompt_source\"].apply(lambda x: isinstance(x, float))].reset_index(drop=True)\n",
    "    # Dropping prompt sources with \\n. pandas read_pickle is not able to handle them properly and drops the rest of the input.\n",
    "    df = df[~df[\"prompt_source\"].str.contains('\\n')].reset_index(drop=True)\n",
    "    # After manual inspection, this example seems to have tokenization issues. 0Dropping.\n",
    "    if task_name == \"star_constellation\":\n",
    "        df = df[~df[\"prompt_source\"].str.contains(\"service\")].reset_index(drop=True)\n",
    "    elif task_name == \"object_superclass\":\n",
    "        df = df[~df[\"prompt_source\"].str.contains(\"Swainson ’ s hawk and the prairie\")].reset_index(drop=True)\n",
    "        \n",
    "    # 对于相同的target_baseline，只保留第一个\n",
    "    df = df.drop_duplicates(subset=[\"target_baseline\"]).reset_index(drop=True)\n",
    "    print(f\"\\tNumber of samples: {len(df)}\")\n",
    "\n",
    "    def evaluate(mt,\n",
    "                 df,\n",
    "                 batch_size=1,  # 修改为1\n",
    "                 max_gen_len=40,\n",
    "                 transform=None,\n",
    "                 only_correct=True,\n",
    "                 is_icl=False\n",
    "                 ):\n",
    "        def evaluate_single_batch(batch_df):\n",
    "            batch_size = len(batch_df)\n",
    "            target_baseline_batch = np.array(batch_df[\"target_baseline\"])\n",
    "            object_batch = np.array(batch_df[\"object\"])\n",
    "            inp_target = make_inputs(mt.tokenizer, target_baseline_batch, mt.device)\n",
    "            seq_len = len(inp_target[\"input_ids\"][0])\n",
    "\n",
    "            \n",
    "            output_toks = mt.model.generate(\n",
    "            inp_target[\"input_ids\"],\n",
    "            max_length=seq_len + max_gen_len,\n",
    "            pad_token_id=mt.model.generation_config.eos_token_id,\n",
    "            # pad_token_id=mt.tokenizer.eos_token_id,\n",
    "            )[:, seq_len:]\n",
    "            \n",
    "            generations_patched = decode_tokens(mt.tokenizer, output_toks)\n",
    "            if is_icl:\n",
    "                prefix = batch_df[\"prefix\"].iloc[0]\n",
    "\n",
    "                def _crop_by_prefix(generations, prefix):\n",
    "                    concatenated_str = \" \".join(generations)\n",
    "                    _pos = concatenated_str.find(prefix)\n",
    "                    return concatenated_str[:_pos]\n",
    "\n",
    "                generations_patched_postprocessed = np.array([\n",
    "                    _crop_by_prefix(generations_patched[i], prefix)\n",
    "                    for i in range(batch_size)\n",
    "                ])\n",
    "            else:\n",
    "                generations_patched_postprocessed = np.array(\n",
    "                [\" \".join(generations_patched[i]) for i in range(batch_size)]\n",
    "            )\n",
    "            \n",
    "            is_correct_patched = np.array([\n",
    "                object_batch[i].replace(\" \", \"\").lower()\n",
    "                in generations_patched_postprocessed[i].replace(\" \", \"\").lower() \n",
    "                for i in range(batch_size)\n",
    "            ])\n",
    "            \n",
    "            result = {\n",
    "                \"is_correct_patched\": is_correct_patched,\n",
    "                \"generations_patched\": generations_patched_postprocessed,\n",
    "            }\n",
    "            return result\n",
    "        \n",
    "        results = {}\n",
    "        n_batches = len(df) // batch_size\n",
    "        if len(df) % batch_size != 0:\n",
    "            n_batches += 1\n",
    "        for i in tqdm(range(n_batches)):\n",
    "            batch_df = df.iloc[i * batch_size:(i + 1) * batch_size] ## iloc函数通过行号来取行数据\n",
    "            result = evaluate_single_batch(batch_df)\n",
    "            for k, v in result.items():\n",
    "                if k not in results:\n",
    "                    results[k] = []\n",
    "                results[k].extend(v)\n",
    "        return results\n",
    "    \n",
    "    eval_results = evaluate(mt, df, batch_size=batch_size)\n",
    "    results_df = df.head(len(eval_results[\"is_correct_patched\"]))\n",
    "    accuracy = np.mean(eval_results[\"is_correct_patched\"])\n",
    "    print (f\"{task_name} Accuracy: {accuracy}\")\n",
    "    for key, value in eval_results.items():\n",
    "        results_df[key] = list(value)\n",
    "\n",
    "    if save_output:\n",
    "        fdir_out = f\"{output_dir}/{task_type}\"\n",
    "        if not os.path.exists(fdir_out):\n",
    "            os.makedirs(fdir_out)\n",
    "        results_df.to_csv(f\"{fdir_out}/{task_name}_only_correct_{only_correct}.tsv\", sep=\"\\t\")\n",
    "        results_df.to_pickle(f\"{fdir_out}/{task_name}_only_correct_{only_correct}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing superhero_person.pkl...\n",
      "Running experiment on factual/superhero_person...\n",
      "\tNumber of samples: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "100%|██████████| 79/79 [01:43<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "  5%|▍         | 1/22 [01:43<36:07, 103.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superhero_person Accuracy: 0.08860759493670886\n",
      "Processing company_ceo.pkl...\n",
      "Running experiment on factual/company_ceo...\n",
      "\tNumber of samples: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [04:24<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "  9%|▉         | 2/22 [06:07<1:05:58, 197.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_ceo Accuracy: 0.3910891089108911\n",
      "Processing person_plays_position_in_sport.pkl...\n",
      "Running experiment on factual/person_plays_position_in_sport...\n",
      "\tNumber of samples: 379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [09:22<00:00,  1.48s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 14%|█▎        | 3/22 [15:30<1:55:26, 364.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_plays_position_in_sport Accuracy: 0.5778364116094987\n",
      "Processing person_plays_pro_sport.pkl...\n",
      "Running experiment on factual/person_plays_pro_sport...\n",
      "\tNumber of samples: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 262/262 [05:52<00:00,  1.35s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 18%|█▊        | 4/22 [21:23<1:47:58, 359.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_plays_pro_sport Accuracy: 0.5076335877862596\n",
      "Processing product_by_company.pkl...\n",
      "Running experiment on factual/product_by_company...\n",
      "\tNumber of samples: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [04:27<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 23%|██▎       | 5/22 [25:50<1:32:33, 326.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_by_company Accuracy: 0.6682926829268293\n",
      "Processing food_from_country.pkl...\n",
      "Running experiment on factual/food_from_country...\n",
      "\tNumber of samples: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.32s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 27%|██▋       | 6/22 [26:10<59:17, 222.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_from_country Accuracy: 0.8666666666666667\n",
      "Processing star_constellation.pkl...\n",
      "Running experiment on factual/star_constellation...\n",
      "\tNumber of samples: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [01:14<00:00,  1.30s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 32%|███▏      | 7/22 [27:24<43:28, 173.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star_constellation Accuracy: 0.7894736842105263\n",
      "Processing country_largest_city.pkl...\n",
      "Running experiment on factual/country_largest_city...\n",
      "\tNumber of samples: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:31<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 55%|█████▍    | 12/22 [27:56<09:25, 56.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_largest_city Accuracy: 1.0\n",
      "Processing country_capital_city.pkl...\n",
      "Running experiment on factual/country_capital_city...\n",
      "\tNumber of samples: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:31<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 59%|█████▉    | 13/22 [28:27<07:51, 52.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_capital_city Accuracy: 0.875\n",
      "Processing country_currency.pkl...\n",
      "Running experiment on factual/country_currency...\n",
      "\tNumber of samples: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:39<00:00,  1.31s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      " 86%|████████▋ | 19/22 [29:07<01:16, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country_currency Accuracy: 0.9666666666666667\n",
      "Processing superhero_archnemesis.pkl...\n",
      "Running experiment on factual/superhero_archnemesis...\n",
      "\tNumber of samples: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [01:54<00:00,  1.32s/it]\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "/tmp/ipykernel_79992/342515986.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results_df[key] = list(value)\n",
      "100%|██████████| 22/22 [31:02<00:00, 84.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superhero_archnemesis Accuracy: 0.3218390804597701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for task_type in [\"factual\"]:\n",
    "    for fname in tqdm(os.listdir(f\"./preprocessed_data/llama2/{task_type}\")):\n",
    "        if fname.endswith('.pkl'):\n",
    "            task_name = fname[:-4]\n",
    "        else:\n",
    "            continue\n",
    "        print(f\"Processing {fname}...\")\n",
    "        run_experiment(task_type, task_name, \"./preprocessed_data/llama2\", \"./single_problem_output/llama2_13b\", only_correct=False, is_icl=False)\n",
    "        ## accuracy表示is_correct_patched的准确率\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 792.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l = 0\n",
    "for task_type in [\"factual\"]:\n",
    "    for fname in tqdm(os.listdir(f\"./preprocessed_data/gpt-j/{task_type}\")):\n",
    "        if fname.endswith('.pkl'):\n",
    "            task_name = fname[:-4]\n",
    "        else:\n",
    "            continue\n",
    "        df = pd.read_pickle(f\"./preprocessed_data/gpt-j/factual/{task_name}.pkl\")\n",
    "        df = df.drop_duplicates(subset=[\"target_baseline\"]).reset_index(drop=True)\n",
    "        l += len(df)\n",
    "        \n",
    "\n",
    "\n",
    "print(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superhero_person_only_correct_False Accuracy: 0.4430379746835443\n",
      "country_capital_city_only_correct_False Accuracy: 0.9166666666666666\n",
      "product_by_company_only_correct_False Accuracy: 0.848780487804878\n",
      "food_from_country_only_correct_False Accuracy: 0.9333333333333333\n",
      "country_largest_city_only_correct_False Accuracy: 1.0\n",
      "country_currency_only_correct_False Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 14/22 [00:00<00:00, 89.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_plays_position_in_sport_only_correct_False Accuracy: 0.7994722955145118\n",
      "person_plays_pro_sport_only_correct_False Accuracy: 0.9694656488549618\n",
      "star_constellation_only_correct_False Accuracy: 0.43859649122807015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 79.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superhero_archnemesis_only_correct_False Accuracy: 0.4827586206896552\n",
      "company_ceo_only_correct_False Accuracy: 0.4603960396039604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path = \"./original_result/llama2/evaluation\"\n",
    "input_path = \"./multi_patch_output/mistral/5_patch/evaluation\"\n",
    "for fname in tqdm(os.listdir(input_path)):\n",
    "    if fname.endswith('.pkl') and \"False\" in fname:\n",
    "        task_name = fname[:-4]\n",
    "    else:\n",
    "        continue\n",
    "    # print(f\"Processing {fname}...\")\n",
    "    df = pd.read_pickle(f\"{input_path}/{task_name}.pkl\")\n",
    "    # 对于相同的subject，只要有一个is_correct_patched为True，就认为是正确的\n",
    "    df = df.groupby(\"subject\").agg({\"is_correct_patched\": \"max\"}).reset_index()\n",
    "\n",
    "    accuracy = np.mean(df[\"is_correct_patched\"])\n",
    "    print(f\"{task_name} Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EasyEdit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
